# Chatbot_SSE.py
from flask import Flask, request, Response, jsonify
from openai import OpenAI
import os, json, requests, re

# --- C·∫•u h√¨nh Flask ---
app = Flask(__name__)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# --- Truy v·∫•n d·ªØ li·ªáu t·ª´ FAISS ---
def query_server(user_input):
    try:
        res = requests.post("http://127.0.0.1:5000/search", json={"query": user_input})
        return res.json() if res.status_code == 200 else []
    except:
        return []

# --- B·ªï sung HTML cho s·∫£n ph·∫©m ---
def enrich_product_data(context_list):
    for item in context_list:
        if isinstance(item, dict) and "h√¨nh_·∫£nh" in item and "id" in item:
            img_path = item["h√¨nh_·∫£nh"]
            sp_id = item["id"]
            item["hinh_html"] = f"""
                <div class='sanpham'>
                    <img src='https://cgi.vn/image/{img_path}' class="product-image">
                    <p>
                        <a href='https://cgi.vn/ar/{sp_id}' target='_blank'>Xem AR</a> |
                        <a href='https://cgi.vn/san-pham/{sp_id}' target='_blank'>Chi ti·∫øt</a>
                    </p>
                </div>
            """
    return context_list

# --- G·ª≠i ph·∫£n h·ªìi d·∫°ng SSE ---
@app.route("/chat-stream", methods=["POST"])
def chat_stream():
    user_input = request.json.get("message", "")
    if not user_input:
        return jsonify({"error": "Missing message"}), 400

    # L·∫•y d·ªØ li·ªáu ng·ªØ c·∫£nh t·ª´ FAISS
    context = enrich_product_data(query_server(user_input))
    context_text = json.dumps(context, ensure_ascii=False)

    messages = [
        {"role": "system", "content": "B·∫°n l√† chuy√™n vi√™n t∆∞ v·∫•n tranh chuy√™n nghi·ªáp, h√£y tr·∫£ l·ªùi t·ª± nhi√™n v√† ch√®n HTML s·∫£n ph·∫©m khi ph√π h·ª£p."},
        {"role": "user", "content": f"Kh√°ch h·ªèi: {user_input}\n\nD·ªØ li·ªáu:\n{context_text}"}
    ]

    def stream():
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.7,
                stream=True
            )

            # G·ª≠i t·ª´ng token ra frontend (typing effect)
            for chunk in response:
                if hasattr(chunk, "choices") and chunk.choices[0].delta.get("content"):
                    content = chunk.choices[0].delta["content"]
                    yield f"data: {json.dumps({'token': content})}\n\n"

            # G·ª≠i ph·∫ßn HTML s·∫£n ph·∫©m (n·∫øu c√≥)
            html_part = "".join([item.get("hinh_html", "") for item in context])
            if html_part:
                yield f"data: {json.dumps({'html': html_part})}\n\n"

            yield "data: [DONE]\n\n"

        except Exception as e:
            yield f"data: {json.dumps({'error': str(e)})}\n\n"

    return Response(stream(), mimetype="text/event-stream")

# --- Ki·ªÉm tra tr·∫°ng th√°i ---
@app.route("/")
def index():
    return jsonify({"status": "ü§ñ Chatbot SSE ƒëang ho·∫°t ƒë·ªông"})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8080)
