from flask import Flask, request, jsonify, render_template
import faiss
import numpy as np
import pickle
import openai
import os
import json
from Chatbot import enrich_product_data, system_prompt
from datetime import datetime

# -----------------------------------------------
# C·∫§U H√åNH API KEY & T·∫¢I FAISS D·ªÆ LI·ªÜU
# -----------------------------------------------
openai.api_key = os.getenv("OPENAI_API_KEY")

BASE_DIR = os.path.dirname(__file__)
FAISS_INDEX_PATH = os.path.join(BASE_DIR, "Vecter_Data", "faiss_index.bin")
METADATA_PATH = os.path.join(BASE_DIR, "Vecter_Data", "metadata.pkl")

# Load FAISS index & metadata
print("üîπ ƒêang t·∫£i d·ªØ li·ªáu FAISS...")
index = faiss.read_index(FAISS_INDEX_PATH)
with open(METADATA_PATH, "rb") as f:
    metadata = pickle.load(f)
print("‚úÖ FAISS s·∫µn s√†ng, t·ªïng s·ªë vector:", len(metadata))

# -----------------------------------------------
# KH·ªûI T·∫†O FLASK APP
# -----------------------------------------------
app = Flask(__name__)

@app.route("/")
def home():
    return "<h2>üöÄ Chatbot FAISS + OpenAI ƒëang ho·∫°t ƒë·ªông!</h2><p>D√πng endpoint POST /chat ƒë·ªÉ g·ª≠i tin nh·∫Øn.</p>"

# -----------------------------------------------
# FAISS SEARCH - x·ª≠ l√Ω t√¨m ki·∫øm n·ªôi b·ªô
# -----------------------------------------------
def search_faiss(user_query):
    if "tranh" not in user_query.lower():
        query = "T√¨m tranh: " + user_query
    else:
        query = user_query

    # Chuy·ªÉn c√¢u truy v·∫•n th√†nh vector
    response = openai.embeddings.create(
        input=[query],
        model="text-embedding-ada-002"
    )
    query_vector = np.array([response.data[0].embedding]).astype("float32")

    # T√¨m c√°c vector t∆∞∆°ng ƒë·ªìng
    k = min(10, len(metadata))
    D, I = index.search(query_vector, k=k)

    results = []
    for idx, dist in zip(I[0], D[0]):
        if idx != -1:
            item = metadata[idx].copy()
            item["distance"] = float(dist)
            results.append(item)

    return results

# -----------------------------------------------
# API /chat - nh·∫≠n message t·ª´ ng∆∞·ªùi d√πng
# -----------------------------------------------
@app.route("/chat", methods=["POST"])
def chat():
    data = request.get_json()
    user_message = data.get("message", "").strip()

    if not user_message:
        return jsonify({"error": "Kh√¥ng c√≥ n·ªôi dung tin nh·∫Øn."}), 400

    # T√¨m k·∫øt qu·∫£ FAISS
    faiss_results = search_faiss(user_message)

    # Chu·∫©n h√≥a d·ªØ li·ªáu s·∫£n ph·∫©m (h√¨nh, link, HTML)
    context_list = enrich_product_data(faiss_results)
    context_text = json.dumps(context_list, ensure_ascii=False, indent=2)

    # T·∫°o l·ªùi nh·∫Øc g·ª≠i cho OpenAI
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"Kh√°ch h·ªèi: {user_message}\n\nD·ªØ li·ªáu s·∫£n ph·∫©m:\n{context_text}"}
    ]

    # G·ªçi OpenAI
    response = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.7
    )

    reply = response.choices[0].message.content

    return jsonify({
        "user": user_message,
        "response": reply,
        "results": context_list
    })

# -----------------------------------------------
# KH·ªûI CH·∫†Y SERVER
# -----------------------------------------------
if __name__ == "__main__":
    from waitress import serve
    port = int(os.environ.get("PORT", 10000))
    print(f"üöÄ Server kh·ªüi ƒë·ªông tr√™n c·ªïng {port}")
    serve(app, host="0.0.0.0", port=port)
